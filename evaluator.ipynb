{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tanmaypilla/AIEarthHack/blob/main/evaluator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Pk-bR4dgrWWD"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import csv\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PoQTkPoUsGF3"
      },
      "source": [
        "## Dataset Processing\n",
        "\n",
        "We first take our dataset of project ideas and store them in a data structure with efficient access. We would then create a baseline model to filter out the ideas using the GPT3.5-API."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FESm_75vs34L",
        "outputId": "a0bb5a1f-2d5a-4558-d7f8-375206cc6413"
      },
      "outputs": [
        {
          "ename": "Error",
          "evalue": "line contains NUL",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mError\u001b[0m                                     Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[7], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/tanmaypilla/AIEarthHack/AI EarthHack Dataset.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, encoding \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatin-1\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m      4\u001b[0m   csv_reader \u001b[38;5;241m=\u001b[39m csv\u001b[38;5;241m.\u001b[39mreader(file)\n\u001b[0;32m----> 5\u001b[0m   header \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcsv_reader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m csv_reader:\n\u001b[1;32m      7\u001b[0m     rows\u001b[38;5;241m.\u001b[39mappend(row)\n",
            "\u001b[0;31mError\u001b[0m: line contains NUL"
          ]
        }
      ],
      "source": [
        "rows = []\n",
        "\n",
        "with open('/Users/tanmaypilla/AIEarthHack/AI EarthHack Dataset.csv', encoding = 'latin-1') as file:\n",
        "  csv_reader = csv.reader(file)\n",
        "  header = next(csv_reader)\n",
        "  for row in csv_reader:\n",
        "    rows.append(row)\n",
        "\n",
        "print(rows[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fuVfD9fNwWdg",
        "outputId": "1b28fd25-237a-453e-ec5b-f4b897aa5821"
      },
      "outputs": [],
      "source": [
        "%pip install openai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQVLNh4kwlyT"
      },
      "source": [
        "## Baseline Model\n",
        "The Baseline Model would"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "y9cHJI7WHq3K"
      },
      "outputs": [],
      "source": [
        "#Baseline model with base metrics :\n",
        "#Adherence to circular economy, market potential, scalability, feasibility, maturity stage, technological innovation\n",
        "baseline_metrics  = {'Market Potential':20, 'Scalability':20,'Feasibility':20,'Maturity Stage':20,'Technological Innovation':20}\n",
        "\n",
        "def generate_baseline_results(idx, problem, solution):\n",
        "      messages = [\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": '''You are an AI-powered decision-support tool to evaluate innovative circular economy business opportunities. You are given a problem statement and a solution. You have to evaluate the solution based on the problem statement and provide a score for the solution. \n",
        "            You are to evaluate the solution based on the following metrics : 'Market Potential', 'Scalability','Feasibility','Maturity Stage','Technological Innovation'. For each metric, you provide a score between 0 and 10. The higher the score, the better the solution.\n",
        "            You must also finally create a combined score, by aggregating all the scores from the metrics above. The score should be between 0 and 100. The higher the score, the better the solution.''',\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": '''Problem Statement : The construction industry is indubitably one of the significant contributors to global waste, contributing approximately 1.3 billion tons of waste annually, exerting significant pressure on our landfills and natural resources. Traditional construction methods entail single-use designs that require frequent demolitions, leading to resource depletion and wastage.\n",
        "                          Solution : Herein, we propose an innovative approach to mitigate this problem: Modular Construction. This method embraces recycling and reuse, taking a significant stride towards a circular economy. Modular construction involves utilizing engineered components in a manufacturing facility that are later assembled on-site. These components are designed for easy disassembling, enabling them to be reused in diverse projects, thus significantly reducing waste and conserving resources. Not only does this method decrease construction waste by up to 90%, but it also decreases construction time by 30-50%, optimizing both environmental and financial efficiency. This reduction in time corresponds to substantial financial savings for businesses. Moreover, the modular approach allows greater flexibility, adapting to changing needs over time. We believe, by adopting modular construction, the industry can transit from a 'take, make and dispose' model to a more sustainable 'reduce, reuse, and recycle' model, driving the industry towards a more circular and sustainable future. The feasibility of this concept is already being proven in markets around the globe, indicating its potential for scalability and real-world application.''',\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"assistant\",\n",
        "            \"content\": \"'Market Potential': 15 /20, 'Scalability': 12 /20,'Feasibility': 19 /20,'Maturity Stage': 14 /20,'Technological Innovation': 11 /20, 'Combined Score': 71 /100\",\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"Problem Statement : \" + problem + \" Solution : \" + solution,\n",
        "        }\n",
        "      ]\n",
        "      \n",
        "      res = OpenAI.chatCompletion.create(\n",
        "          model = \"gpt-3.5-turbo\",\n",
        "          messages = messages\n",
        "      )\n",
        "      result = [idx, problem, solution, res.choices[0][\"message\"][\"content\"][3], res.choices[0][\"message\"][\"content\"][8], res.choices[0][\"message\"][\"content\"][14], res.choices[0][\"message\"][\"content\"][19]]\n",
        "      return result\n",
        "\n",
        "def baseline_model():\n",
        "  with open('/content/sample_data/baseline_results.csv','w', encoding = 'latin-1') as file:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ax0CA4kDKIIV"
      },
      "source": [
        "## User-Based Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gAVLY95IKNng"
      },
      "outputs": [],
      "source": [
        "#User-based model\n",
        "import os\n",
        "from openai import OpenAI\n",
        "\n",
        "api_key = \"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\"\n",
        "client = OpenAI(api_key=api_key)\n",
        "\n",
        "def user_model():\n",
        "    chat_completion = client.chat.completions.create(\n",
        "        messages=[\n",
        "            { \"role\": \"user\",\"content\": \"Say this is a test\", }\n",
        "        ],\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "    )\n",
        "    print(chat_completion.choices[0].message)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
